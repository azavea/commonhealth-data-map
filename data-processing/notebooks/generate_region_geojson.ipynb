{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate regions GeoJSON\n",
    "\n",
    "This notebook combines the admin1 boundaries with country-specific regions that can be matched against for datasets that work with sub-national regions. Not all data that works with regions match exactly to Natural Earth's Admin1 boundaries; we add in country-specific region data for cases where we need another breakdown of a country's regions. This GeoJSON will therefor contain overlapping polygons for regions that have both admin1 and country-specific region boundaries.\n",
    "\n",
    "The features produced by this processing will contain the following columns:\n",
    "\n",
    "- `name`: The name of the region.\n",
    "- `name_en`: Optionally an alternate name in english, used for matching.\n",
    "- `iso_a2`: the ISO Alpha 2 code of the country the region belongs to.\n",
    "\n",
    "The region data is set up to match with both Google mobility data and JHU regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static, should not need to be run through the update\n",
    "data_dir = '/opt/src/data'\n",
    "region_data_dir = '/opt/src/data/regions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "from shapely.geometry import mapping\n",
    "from shapely.algorithms.polylabel import polylabel\n",
    "import pycountry\n",
    "from shapely.ops import cascaded_union\n",
    "from jenkspy import jenks_breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(geom, iso_a2, name, name_en=None):\n",
    "    features.append(\n",
    "        {\n",
    "            'type': 'Feature',\n",
    "            'geometry': geom if type(geom) is dict else mapping(geom),\n",
    "            'properties': {\n",
    "                'iso_a2': iso_a2,\n",
    "                'name': name,\n",
    "                'name_en': name_en\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'name',\n",
    "    'name_en',\n",
    "    'iso_a2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin1_gdf = gpd.read_file(os.path.join(region_data_dir,'admin1.geojson'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in admin1_gdf.iterrows():\n",
    "    add_feature(row['geometry'], \n",
    "                row['iso_a2'], \n",
    "                row['name'], \n",
    "                row['name_en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spain\n",
    "spain_gdf = gpd.read_file(os.path.join(region_data_dir, 'spain-comunidad.json'))\n",
    "\n",
    "for _, row in spain_gdf.iterrows():\n",
    "    add_feature(row['geometry'], \n",
    "                'ES', \n",
    "                row['NAME_1'])\n",
    "    \n",
    "# Spain - Canary Islands\n",
    "\n",
    "canary_islands_gdf = gpd.read_file(os.path.join(region_data_dir, 'canary-islands-province.json'))\n",
    "\n",
    "for _, row in canary_islands_gdf.iterrows():\n",
    "    add_feature(row['geometry'], \n",
    "                'ES', \n",
    "                'Canary Islands')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Italy\n",
    "italy_gdf = gpd.read_file(os.path.join(region_data_dir, 'italy_regions.geojson'))\n",
    "\n",
    "for _, row in italy_gdf.iterrows():\n",
    "    add_feature(row['geometry'], \n",
    "                'IT', \n",
    "                row['reg_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Belgium\n",
    "be_regions = {\n",
    "    'Flanders': ['East Flanders', 'West Flanders', \n",
    "                 'Limburg', 'Antwerp', 'Flemish Brabant'],\n",
    "    'Wallonia': ['Hainaut', 'Liege', 'Luxembourg',\n",
    "                 'Namur','Walloon Brabant' ]\n",
    "}\n",
    "\n",
    "for r in be_regions:\n",
    "    add_feature(cascaded_union(admin1_gdf[\n",
    "                    (admin1_gdf['iso_a2'] == 'BE') & \n",
    "                    (admin1_gdf['name'].isin(be_regions[r]))\n",
    "                ]['geometry']),\n",
    "                'BE',\n",
    "                r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# France\n",
    "france_gdf = gpd.read_file(os.path.join(region_data_dir, 'france-regions.geojson'))\n",
    "\n",
    "for _, row in france_gdf.iterrows():\n",
    "    add_feature(row['geometry'], \n",
    "                'FR', \n",
    "                row['nom'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/opt/src/data/gb-counties'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0a756aebbd29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcounties_accounted_for\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgb_admin1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madmin1_gdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madmin1_gdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iso_a2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GB'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gb-counties'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gb-counties'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/opt/src/data/gb-counties'"
     ]
    }
   ],
   "source": [
    "# Great Britian\n",
    "\n",
    "gb_regions = {\n",
    "    'Mid And East Antrim': ['Ballymena', 'Larne', 'Carrickfergus'],\n",
    "    'Lisburn and Castlereagh': ['Lisburn', 'Castlereagh'],\n",
    "    'Fermanagh And Omagh': ['Fermanagh','Omagh'],\n",
    "    'Derry And Strabane': ['Derry','Strabane'],\n",
    "    'Causeway Coast and Glens': ['Ballymoney','Coleraine', 'Limavady', 'Moyle'],\n",
    "    'Armagh City, Banbridge And Craigavon':['Armagh', 'Banbridge', 'Craigavon'],\n",
    "    'Ards And North Down': ['Ards','North Down'],\n",
    "    'Antrim And Newtownabbey': ['Antrim','Newtownabbey']\n",
    "}\n",
    "\n",
    "counties_accounted_for = set([])\n",
    "gb_admin1 = set(admin1_gdf[admin1_gdf['iso_a2'] == 'GB']['name'])\n",
    "for path in os.listdir(os.path.join(data_dir, 'gb-counties')):\n",
    "    with open(os.path.join(data_dir, 'gb-counties', path)) as f:\n",
    "        feat = json.loads(f.read())\n",
    "        name = feat['properties']['name']\n",
    "        if not name in gb_admin1:\n",
    "            feat['properties'] = {\n",
    "                'name': name,\n",
    "                'name_en': None,\n",
    "                'iso_a2':  'GB'\n",
    "            }\n",
    "            features.append(feat)\n",
    "        \n",
    "for r in gb_regions:\n",
    "    add_feature(cascaded_union(admin1_gdf[\n",
    "                    (admin1_gdf['iso_a2'] == 'GB') & \n",
    "                    (admin1_gdf['name'].isin(gb_regions[r]))\n",
    "                ]['geometry']),\n",
    "                'GB',\n",
    "                r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greece\n",
    "\n",
    "gr_regions = {\n",
    "    'Decentralized Administration of Epirus and Western Macedonia': [\n",
    "        'Ipeiros', 'Dytiki Makedonia'\n",
    "    ],\n",
    "    'Decentralized Administration of Macedonia and Thrace': [\n",
    "        'Kentriki Makedonia', 'Anatoliki Makedonia kai Thraki'\n",
    "    ],\n",
    "    'Decentralized Administration of Peloponnese, Western Greece and the Ionian': [\n",
    "        'Peloponnisos', 'Dytiki Ellada', 'Ionioi Nisoi'\n",
    "    ],\n",
    "    'Decentralized Administration of the Aegean': [\n",
    "        'Notio Aigaio', 'Voreio Aigaio'\n",
    "    ],\n",
    "    'Decentralized Administration of Thessaly and Central Greece': [\n",
    "        'Thessalia', 'Stereá Elláda'\n",
    "    ]\n",
    "}\n",
    "\n",
    "for r in gr_regions:\n",
    "    add_feature(cascaded_union(admin1_gdf[\n",
    "                    (admin1_gdf['iso_a2'] == 'GR') & \n",
    "                    (admin1_gdf['name'].isin(gr_regions[r]))\n",
    "                ]['geometry']),\n",
    "                'GR',\n",
    "                r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Kenya \n",
    "kenya_gdf = gpd.read_file(os.path.join(region_data_dir, 'kenya-counties.geojson'))\n",
    "\n",
    "for _, row in kenya_gdf.iterrows():\n",
    "    if not row['COUNTY_NAM']:\n",
    "        continue\n",
    "    name = row['COUNTY_NAM'].capitalize() \\\n",
    "            .replace(' - ', '-') \\\n",
    "            .replace(' ', '-') + ' County'\n",
    "    add_feature(row['geometry'], \n",
    "                'KE', \n",
    "                name)\n",
    "                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norway\n",
    "\n",
    "no_gdf = gpd.read_file(os.path.join(region_data_dir, 'norway-counties.geojson'))\n",
    "no_admin1 = set(admin1_gdf[admin1_gdf['iso_a2'] == 'NO']['name'])\n",
    "\n",
    "for _, row in no_gdf.iterrows():\n",
    "    name = row['navn']\n",
    "    if not name in no_admin1:\n",
    "        add_feature(row['geometry'], \n",
    "                    'NO', \n",
    "                    name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sorted(features, key=lambda f: (\n",
    "    f['properties']['iso_a2'], \n",
    "    'x' if f['properties']['name'] is None else f['properties']['name']\n",
    "))\n",
    "for i, f in enumerate(features):\n",
    "    f['properties']['id'] = i\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'published/regions.geojson'), 'w') as f:\n",
    "    f.write(json.dumps(fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
