{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process JHU Data\n",
    "\n",
    "This notebook downloads the latest JHU data from GitHub, processes it for dashboard visualization, and places it in the published folder.\n",
    "\n",
    "### Papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "data_dir = '/opt/src/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For papermill execution, the pameters are:\n",
    "- data_dir: That data directory to read data from and publish data to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, shape\n",
    "from slugify import slugify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "eac_countries = [\n",
    "    'Burundi',\n",
    "    'Kenya',\n",
    "    'Rwanda',\n",
    "    'South Sudan',\n",
    "    'Tanzania',\n",
    "    'Uganda'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_df(url):\n",
    "    \"\"\"Fetches a Pandas DataFrame from a remote source\"\"\"\n",
    "    r = requests.get(url)\n",
    "    return pd.read_csv(io.BytesIO(r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the JHU data from it's source on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_df = fetch_df('https://github.com/CSSEGISandData/COVID-19/raw/master/'\n",
    "                    'csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "deaths_df = fetch_df('https://github.com/CSSEGISandData/COVID-19/raw/master/'\n",
    "                     'csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "recovered_df= fetch_df('https://github.com/CSSEGISandData/COVID-19/raw/master/'\n",
    "                       'csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the lat/lng of Congo, which is the same as the Democratic Republic of Congo in the JHU data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congo_ll = [-1.402385, 15.405892]\n",
    "def fix_congo(df):\n",
    "    df.loc[df['Country/Region'] == 'Congo (Brazzaville)', 'Lat'] = congo_ll[0]\n",
    "    df.loc[df['Country/Region'] == 'Congo (Brazzaville)', 'Long'] = congo_ll[1]\n",
    "fix_congo(cases_df)\n",
    "fix_congo(deaths_df)\n",
    "fix_congo(recovered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge in the USecounty data. This data only has cases and deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cases_df = fetch_df('https://github.com/CSSEGISandData/COVID-19/raw/master/'\n",
    "                    'csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')\n",
    "us_deaths_df = fetch_df('https://github.com/CSSEGISandData/COVID-19/raw/master/'\n",
    "                     'csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_deaths_df[us_deaths_df.iloc[:,-1] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_territories = [\n",
    "    'American Samoa',\n",
    "    'Guam',\n",
    "    'Northern Mariana Islands',\n",
    "    'Puerto Rico',\n",
    "    'Virgin Islands'\n",
    "]\n",
    "\n",
    "def filter_and_reformat_us(df):\n",
    "    # Filter out counties that have 0 latest data.\n",
    "    filtered_df = df[df.iloc[:,-1] != 0]\n",
    "    filtered_df = filtered_df[\n",
    "        (filtered_df['Province_State'].isin(us_territories)) |\n",
    "        (\n",
    "            (~filtered_df['Lat'].isnull()) &\n",
    "            (filtered_df['Lat'] != 0.0) &\n",
    "            (~filtered_df['FIPS'].isnull())\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    columns_to_drop = [\n",
    "        'UID',\n",
    "        'iso2',\n",
    "        'iso3',\n",
    "        'code3',\n",
    "        'FIPS',\n",
    "        'Admin2',\n",
    "        'Province_State',\n",
    "        'Country_Region',\n",
    "        'Combined_Key',\n",
    "        'Long_'\n",
    "    ]\n",
    "    \n",
    "    def set_prov(row):        \n",
    "        prov = row['Province_State']\n",
    "        if row['Admin2'] and (type(row['Admin2']) != float or not np.isnan(row['Admin2'])):\n",
    "            prov = '{} - {}'.format(row['Admin2'], prov)\n",
    "        return prov\n",
    "\n",
    "    formatted_df = filtered_df.copy()\n",
    "    formatted_df['Province/State'] = formatted_df.apply(set_prov, axis=1)\n",
    "    formatted_df['Country/Region'] = formatted_df['Country_Region']\n",
    "    formatted_df['Long'] = formatted_df['Long_']\n",
    "    formatted_df = formatted_df.drop(columns=columns_to_drop)\n",
    "    return formatted_df\n",
    "    \n",
    "formatted_us_cases_df = filter_and_reformat_us(us_cases_df)\n",
    "formatted_us_deaths_df = filter_and_reformat_us(us_deaths_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map out the formatted dates for each date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_date_columns = ['Province/State', 'Country/Region', 'Lat', 'Long']\n",
    "date_columns = list(set(cases_df.columns) - set(non_date_columns))\n",
    "\n",
    "dates_to_format = {}\n",
    "for d in date_columns:\n",
    "    dt = datetime.strptime(d, '%m/%d/%y')\n",
    "    dates_to_format[d] = dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code gathers the data in an intermediate dictionary, keyed to a region ID that made out of a tuple of the admin0 and admin1 column values. The values represent the total confirmed cases, deaths, and recovered patients for each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gathered = {}\n",
    "\n",
    "# Setup multi-national entries\n",
    "# Data points with the 'points' property set to None don't display on the map.\n",
    "global_key = ('global', None)\n",
    "eac_key = ('EAC', None)\n",
    "gathered[global_key] = { 'point': None, 'dates': {} }\n",
    "gathered[eac_key] = { 'point': None, 'dates': {} }\n",
    "\n",
    "\n",
    "def add_multinational_cases(key, dt, cases):\n",
    "    if not dt in gathered[key]['dates']:\n",
    "        gathered[key]['dates'][dt] = [cases, 0, 0]\n",
    "    else:\n",
    "        (prev_c, _, _) = gathered[key]['dates'][dt]\n",
    "        gathered[key]['dates'][dt] = [cases + prev_c, 0, 0]\n",
    "        \n",
    "def add_multinational_deaths(key, dt, deaths):\n",
    "    (prev_c, total_d, _) = gathered[key]['dates'][dt]\n",
    "    if total_d is None:\n",
    "        total_d = deaths\n",
    "    else:\n",
    "        total_d += deaths\n",
    "    gathered[key]['dates'][dt] = [prev_c, total_d, 0]\n",
    "    \n",
    "def add_multinational_recovered(key, dt, recovered):\n",
    "    (prev_c, prev_d, total_r) = gathered[key]['dates'][dt]\n",
    "    if total_r is None:\n",
    "        total_r = recovered\n",
    "    else:\n",
    "        total_r += recovered\n",
    "    gathered[key]['dates'][dt] = [prev_c, prev_d, total_r]\n",
    "\n",
    "## Note:\n",
    "# It was requested to put in US county data. This caused a general\n",
    "# site slowdown. Commenting out the inclusion of US county data\n",
    "# until we rework how we're loading things - e.g. shifting to \n",
    "# a vector tile approach.\n",
    "\n",
    "#for _, row in pd.concat([cases_df, formatted_us_cases_df]).iterrows():\n",
    "for _, row in cases_df.iterrows():\n",
    "    admin0 = row['Country/Region']\n",
    "    admin1 = row['Province/State']\n",
    "    if type(admin1) is float and np.isnan(admin1):\n",
    "        admin1 = None\n",
    "    lat = row['Lat']\n",
    "    lng = row['Long']\n",
    "    gathered[(admin0, admin1)] = { 'point': [lng, lat], 'dates': {} }\n",
    "    for d in date_columns:\n",
    "        cases = row[d]\n",
    "        dt = dates_to_format[d]\n",
    "        gathered[(admin0, admin1)]['dates'][dt] = [cases, 0, 0]\n",
    "        \n",
    "        add_multinational_cases(global_key, dt, cases)\n",
    "\n",
    "        if admin0 in eac_countries:\n",
    "            add_multinational_cases(eac_key, dt, cases)\n",
    "\n",
    "#for _, row in pd.concat([deaths_df, formatted_us_deaths_df]).iterrows():\n",
    "for _, row in deaths_df.iterrows():\n",
    "    admin0 = row['Country/Region']\n",
    "    admin1 = row['Province/State']\n",
    "    if type(admin1) is float and np.isnan(admin1):\n",
    "        admin1 = None\n",
    "\n",
    "    for d in date_columns:\n",
    "        deaths = row[d]\n",
    "        dt = dates_to_format[d]\n",
    "        if (admin0, admin1) not in gathered or dt not in gathered[(admin0, admin1)]['dates']:\n",
    "            continue\n",
    "            \n",
    "        gathered[(admin0, admin1)]['dates'][dt][1] = deaths\n",
    "        \n",
    "        add_multinational_deaths(global_key, dt, deaths)\n",
    "\n",
    "        if admin0 in eac_countries:\n",
    "            add_multinational_deaths(eac_key, dt, deaths)\n",
    "\n",
    "for _, row in recovered_df.iterrows():\n",
    "    admin0 = row['Country/Region']\n",
    "    admin1 = row['Province/State']\n",
    "    if type(admin1) is float and np.isnan(admin1):\n",
    "        admin1 = None\n",
    "\n",
    "    for d in date_columns:\n",
    "        recovered = row[d]\n",
    "        dt = dates_to_format[d]\n",
    "        # Skip canada as it doesn't match up with the other datasets\n",
    "        if (admin0, admin1) != ('Canada', None):\n",
    "            gathered[(admin0, admin1)]['dates'][dt][2] = recovered\n",
    "\n",
    "        add_multinational_recovered(global_key, dt, recovered)\n",
    "\n",
    "        if admin0 in eac_countries:\n",
    "            add_multinational_recovered(eac_key, dt, recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max date and latest counts for EAC countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = sorted(gathered[eac_key]['dates'], reverse=True)[0]\n",
    "print('MAX DATE: {}'.format(max_date))\n",
    "print('\\nCountry counts:')\n",
    "for x in eac_countries:\n",
    "    print('  {}: {}'.format(x, gathered[(x, None)]['dates'][max_date]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a map of continent names to continent geometries so that we can find the continent for each point geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = {}\n",
    "\n",
    "with open(os.path.join(data_dir, 'continents.geojson')) as f:\n",
    "    continents_js = json.loads(f.read())\n",
    "    for f in continents_js['features']:\n",
    "        continents[f['properties']['CONTINENT']] = shape(f['geometry'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the gathered data and construct the JSON file that is used to display the data in the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continent(admin0, admin1, info):\n",
    "    if admin0 in ['Diamond Princess', 'MS Zaandam']:\n",
    "        # Skip the cruise ships\n",
    "        return None\n",
    "    \n",
    "    # Skip multinational regions\n",
    "    if info['point'] is None:\n",
    "        return None\n",
    "    \n",
    "    result = None\n",
    "    if admin0 in ['Cabo Verde', 'EAC']:\n",
    "        result = 'Africa'\n",
    "    elif admin0 in ['US', 'Canada', 'Saint Vincent and the Grenadines']:\n",
    "        result = 'North America'\n",
    "    elif admin0 in ['China', 'Maldives', 'Philippines']:\n",
    "        result = 'Asia'\n",
    "    elif admin0 in ['Denmark', 'France', 'Monaco', 'United Kingdom']:\n",
    "        result = 'Europe'\n",
    "    elif admin0 in ['New Zealand']:\n",
    "        result = 'Oceania'\n",
    "    elif admin1 in ['Aruba']:\n",
    "        result = 'South America'\n",
    "    elif admin1 in ['Sint Maarten']:\n",
    "        result = 'North America'\n",
    "    else:\n",
    "        p = Point(*info['point'])\n",
    "\n",
    "        for c in continents:\n",
    "            if continents[c].intersects(p):\n",
    "                result = c\n",
    "        if result is None:\n",
    "            print(info)\n",
    "            raise Exception('Continent not found for \"{}\" - \"{}\"'.format(admin0, admin1))\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_area(admin0, admin1, info):\n",
    "    result = []\n",
    "    continent = get_continent(admin0, admin1, info)\n",
    "    \n",
    "    slug_txt = admin0\n",
    "    if admin1 is not None:\n",
    "        slug_txt = \"{} {}\".format(admin1, admin0)\n",
    "    code = slugify(slug_txt)\n",
    "    \n",
    "    sorted_dates = sorted(gathered[(admin0, admin1)]['dates'])\n",
    "\n",
    "    (prev_cases,\n",
    "     prev_deaths,\n",
    "     prev_recovered,\n",
    "     prev_active) = (None,\n",
    "                     None,\n",
    "                     None,\n",
    "                     None)\n",
    "\n",
    "    for date in sorted_dates:\n",
    "             \n",
    "        (cases,\n",
    "         deaths,\n",
    "         recovered) = gathered[(admin0, admin1)]['dates'][date]\n",
    "\n",
    "        active = cases - deaths - recovered\n",
    "\n",
    "        (cases_change,\n",
    "         deaths_change,\n",
    "         recovered_change,\n",
    "         active_change) = (None,\n",
    "                           None,\n",
    "                           None,\n",
    "                           None)\n",
    "\n",
    "        if prev_cases is not None:\n",
    "            cases_change = cases - prev_cases\n",
    "            deaths_change = deaths - prev_deaths\n",
    "            recovered_change = recovered - prev_recovered\n",
    "            active_change = active - prev_active\n",
    "\n",
    "        \n",
    "        result.append({\n",
    "            'name': admin0,\n",
    "            'admin1': admin1,\n",
    "            'continent': continent,\n",
    "            'date': date,\n",
    "            'cases': cases,\n",
    "            'cases_change': cases_change,\n",
    "            'deaths': deaths,\n",
    "            'deaths_change': deaths_change,\n",
    "            'recovered': recovered,\n",
    "            'recovered_change': recovered_change,\n",
    "            'active': active,\n",
    "            'active_change': active_change,\n",
    "            'code': code,\n",
    "            'coordinates': info['point']\n",
    "        })\n",
    "\n",
    "        (prev_cases,\n",
    "         prev_deaths,\n",
    "         prev_recovered,\n",
    "         prev_active) = (cases,\n",
    "                         deaths,\n",
    "                         recovered,\n",
    "                         active)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_js = []\n",
    "for key in sorted(gathered.keys(), key=lambda x: '{}_{}'.format(x[0], x[1])):\n",
    "    admin0, admin1 = key\n",
    "    info = gathered[key]\n",
    "    output_js.extend(process_area(admin0, admin1, info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for latest_eac_entry in [\n",
    "    json.dumps(js, indent=4) \n",
    "    for js in output_js \n",
    "    if js['name'] in eac_countries and\n",
    "    js['date'] == max_date\n",
    "]:\n",
    "    print(latest_eac_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(data_dir, 'published/jhu-case-data.json')\n",
    "\n",
    "open(output_file, 'w').write(json.dumps(output_js, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
